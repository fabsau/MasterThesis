########################################
# 1. DATABASE
########################################

# Hostname of your Postgres server
DB_HOST=localhost

# Port of your Postgres server
DB_PORT=5432

# Database name
DB_NAME=catlyst

# Username for your database
DB_USER=catlyst

# Password for your database (REQUIRED)
DB_PASSWORD=supersecretpassword

########################################
# 2. SENTINELONE
########################################

# URL to the SentinelOne management API (REQUIRED)
S1_MANAGEMENT_URL=https://management.sentinelone.net

# Your SentinelOne API token (REQUIRED)
S1_API_TOKEN=api_token_here

# API version (default: v2.1)
S1_API_VERSION=v2.1

# Verify SSL certificates? (default: true)
S1_VERIFY_SSL=true

# Maximum items per page when listing resources
S1_PAGE_LIMIT=1000

# Maximum items per page when fetching notes
S1_NOTE_PAGE=1000

# Maximum number of concurrent workers for API calls
S1_MAX_WORKERS=200

# Timeout (in seconds) for deep-visibility fetches
S1_DV_TIMEOUT=120.0

# How many times to retry initialization on failure
S1_MAX_INIT_RETRY=5

# Look-back window (in days) for main data pulls
S1_LOOKBACK_DAYS=1

# Max incident look-back window (in days)
S1_MAX_INCIDENT_LOOKBACK_DAYS=365

# Max deep-visibility look-back window (in days)
S1_MAX_DEEPVIS_LOOKBACK_DAYS=90

########################################
# 3. ETL / CLI
########################################

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Timestamp format for output
ISO_FORMAT="%Y-%m-%dT%H:%M:%SZ"

# How many days back to pull by default
SINCE_DAYS=1

# Absolute max days back allowed
MAX_SINCE_DAYS=365

# Comma-separated list of verdicts to include
VERDICTS=true_positive,false_positive

# Skip progress bar output? (default: false)
NO_PROGRESS=false

# Number of worker threads for ETL
WORKERS=200

# Output file for raw JSON
OUTPUT_FILE=./data/raw.json

# Comma-separated top-level fields to ignore in ETL
IGNORE_FIELDS=

# Comma-separated nested fields to ignore in ETL
IGNORE_NESTED_FIELDS=

########################################
# 4. TABLE
########################################

# Name of the table to write threats into
DB_TABLE_THREATS=catlyst

########################################
# 5. SPLIT
########################################

# Path to the raw JSON input
INPUT_FILE=./data/raw.json

# Directory where split outputs will be written
OUT_DIR=./data/splits

# Fraction of data to hold out as test set
TEST_SIZE=0.2

# Cutoff date (YYYY-MM-DD) for temporal split
CUTOFF_DATE=2025-05-01

# Split methods: comma-separated
METHODS=random,group,time,temporal-group

# RNG seed for reproducibility
SEED=42

# Optional cap on total threats (omit or leave empty for no cap)
MAX_THREATS=

# Dot-path to timestamp field in each record
TIME_FIELD=threatInfo.createdAt

# Comma-separated list of fields to group by
GROUP_FIELDS=threatInfo.sha1,threatInfo.sha256,threatInfo.md5,threatInfo.threatId

# Unique-ID field for grouping
ID_FIELD=threatInfo.threatId

########################################
# 6. CATBOOST
########################################

# Training JSON produced by your splitter
TRAIN_JSON=./data/splits/temporal-group/train.json

# Testing JSON produced by your splitter
TEST_JSON=./data/splits/temporal-group/test.json

# Output path for the trained CatBoost model
MODEL_OUT=./models/s1_fp_detector.cbm

# Directory to dump evaluation results
RESULTS_DIR=./results

# Number of threads CatBoost may use
THREADS=8

# (Optional) JSON-encoded CatBoost parameters override.
# Leave unset to use defaults in code.
# CATBOOST_PARAMS='{"iterations":2000,"learning_rate":0.05,"depth":8}'


########################################
# 7. INFERENCE
########################################

# (Optional) Path to a pre-trained CatBoost model for inference
MODEL_PATH=

# (Optional) Path to the model's metadata (e.g. feature mapping)
META_PATH=

# (Optional) Path to input JSON file for inference
INPUT_JSON=

# (Optional) Output file for inference results
OUTPUT_JSON=

# (Optional) Data file to train a novelty detector on
NOVELTY_TRAIN=

# IsolationForest contamination default
ISO_CONT_DEFAULT=0.01

# IsolationForest estimators default
ISO_EST_DEFAULT=200

# Novelty threshold (distance) default
NOVELTY_THRESHOLD=0.0

# Probability threshold for binary classification
PROB_THRESHOLD=0.5

########################################
# 8. ADDITIONAL PROCESSING
########################################

# -----------------
# Whitelist Settings
# -----------------

# Dot-paths of top-level fields to keep in your final payload
WHITELIST_FIELDS=threatInfo.threatId,threatInfo.storyline,threatInfo.createdAt,threatInfo.analystVerdict,threatInfo.detectionEngines,threatInfo.sha1,threatInfo.sha256,threatInfo.md5,deepVisibilityEvents,indicators,notes

# -----------------
# DeepVis Settings
# -----------------

# Comma-separated DeepVisibility columns to use
DEEPVIS_COLUMNS=event.type,event.category,severity

# Field on which to sort deep-visibility events
DEEPVIS_SORT=event.time

# -----------------
# Feature Extraction
# -----------------

# Path to JSON for feature extraction
RAW_JSON_PATH=./data/splits/temporal-group/train.json

# Output CSV path for features
FEATURES_OUTPUT_CSV=./data/staging/features.csv

# Top-level fields to process for ETL
ETL_TOP_LEVEL_FIELDS=threatInfo,deepVisibilityEvents,indicators,notes

# Numeric fields to coerce/process separately
ETL_PROC_NUMERIC=

# Maximum length for concatenated notes
ETL_NOTES_MAX_LEN=5000

# -----------------
# TF-IDF Settings
# -----------------

# Maximum TF-IDF features
TFIDF_MAX_FEATURES=500

# N-gram range for TF-IDF as two ints separated by comma
TFIDF_NGRAM_RANGE=1,2

# Stop-word language for TF-IDF ("english","german", etc.) or blank
TFIDF_STOP_WORDS=german

# -----------------
# SMOTE Settings
# -----------------

SMOTE_SAMPLING_STRATEGY=0.3
SMOTE_RANDOM_STATE=42

# -----------------
# Cross-Validation Settings
# -----------------

CV_FOLDS=5
CV_SHUFFLE=true
CV_RANDOM_STATE=42